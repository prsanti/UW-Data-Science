{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjflwbWmfERQ",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Module 11: Using TensorFlow Interactively and Using Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will cover how to use TensorFlow like NumPy and introduce how to create tailored custom models for applications where using the Keras high-level API will be awkward or insufficient.\n",
    "\n",
    "We will also look at how to save and restore models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, you will develop the knowledge and skills to use TensorFlow (TF) Python API. This will include:\n",
    "\n",
    "- Using TensorFlow interatively\n",
    "- Customizing models\n",
    "- Saving and restoring models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readings and Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRDWZIPsfERT"
   },
   "source": [
    "We invite you to further supplement this notebook with the following recommended texts/resources.\n",
    "\n",
    "- Géron, A. (2019). Chapter 12: Custom Models and Training with TensorFlow in *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* (2nd ed.). O’Reilly Media. https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\n",
    "\n",
    "\n",
    "- TensorFlow documentation and tutorials: https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\">\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Module-11:-Using-TensorFlow-Interactively-and-Using-Custom-Functions\" data-toc-modified-id=\"Module-11:-Using-TensorFlow-Interactively-and-Using-Custom-Functions\">Module 11: Using TensorFlow Interactively and Using Custom Functions</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction\">Introduction</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Learning-Outcomes\" data-toc-modified-id=\"Learning-Outcomes\">Learning Outcomes</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Readings-and-Resources\" data-toc-modified-id=\"Readings-and-Resources\">Readings and Resources</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Table-of-Contents\" data-toc-modified-id=\"Table-of-Contents\">Table of Contents</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#An-overview-of-TensorFlow\" data-toc-modified-id=\"An-overview-of-TensorFlow\">An overview of TensorFlow</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#How-TensorFlow-works\" data-toc-modified-id=\"How-TensorFlow-works\">How TensorFlow works</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#TensorFlow-benefits\" data-toc-modified-id=\"TensorFlow-benefits\">TensorFlow benefits</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#TensorFlow-alternatives\" data-toc-modified-id=\"TensorFlow-alternatives\">TensorFlow alternatives</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Computation-graphs\" data-toc-modified-id=\"Computation-graphs\">Computation graphs</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Using-TensorFlow-interactively\" data-toc-modified-id=\"Using-TensorFlow-interactively\">Using TensorFlow interactively</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Basic-mathematical-operations\" data-toc-modified-id=\"Basic-mathematical-operations\">Basic mathematical operations</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Differences-from-NumPy\" data-toc-modified-id=\"Differences-from-NumPy\">Differences from NumPy</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables\">Variables</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Other-TF-data-structures\" data-toc-modified-id=\"Other-TF-data-structures\">Other TF data structures</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Custom-functions\" data-toc-modified-id=\"Custom-functions\">Custom functions</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Custom-loss\" data-toc-modified-id=\"Custom-loss\">Custom loss</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Saving-and-reloading-models\" data-toc-modified-id=\"Saving-and-reloading-models\">Saving and reloading models</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Custom-activation-functions,-initializers,-regularizers,-and-constraints\" data-toc-modified-id=\"Custom-activation-functions,-initializers,-regularizers,-and-constraints\">Custom activation functions, initializers, regularizers, and constraints</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#References\" data-toc-modified-id=\"References\">References</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An overview of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LzqYeqxdfERV"
   },
   "source": [
    "## How TensorFlow works\n",
    "\n",
    "TensorFlow uses **dataflow graphs**, which are essentially structures that describe how data moves through a graph, or a series of processing nodes. Each node in the graph represents a mathematical operation, and each connection or edge between nodes is a multidimensional data array, or **tensor** (this will be discussed in more detail in the next section). \n",
    "\n",
    "In TensorFlow 1 a user would explicitly construct and run the graph.  TensorFlow 2 allows us to work interactively more like the way we use NumPy, with each operation executed immediately (\"eagerly\") when we are experimenting and provides higher level tools such as [tf.function](https://www.tensorflow.org/guide/basics#graphs_and_tffunction) and Keras to construct the graphs for us when we actually need them.\n",
    "\n",
    "It is important to note that the actual **math operations are not performed in Python**. The libraries of transformations that TensorFlow provides are written as high-performance C++ binaries so TF runs much faster than an implementation completely in Python would be capable of. **Python just directs traffic between the pieces, and provides simple and high-level programming abstractions to connect all of the pieces together.**\n",
    "\n",
    "TensorFlow applications can be run on pretty much any platform or machine: your local computer, iOS and Android devices, a cluster in the cloud, CPUs or GPUs, even in a browser. If you use Google’s cloud platform, you can run TensorFlow on Google’s custom-designed TensorFlow Processing Units (TPUs) for even greater processing speed. That said, **regardless of what machine you use to train your model, the resulting models created can be deployed on almost any device with a proper TensorFlow installation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nuA20vqPfERW"
   },
   "source": [
    "## TensorFlow benefits\n",
    "\n",
    "The single greatest benefit TensorFlow provides for Neural Network model development is abstraction. The relatively simple API allows the developer to focus on the overall logic of their application, rather than getting bogged down by the nitty-gritty details of implementing complex neural network architectures.\n",
    "\n",
    "TensorFlow makes parallel processing across multiple CPUs or GPUs fairly simple (at least from the developer's standpoint). TensorFlow also supports distributed computing, so you can train colossal neural networks on humongous training sets in a reasonable amount of time by splitting the computations across hundreds of servers if required. In fact, **TensorFlow can train a network with millions of parameters on a data set composed of billions of instances with millions of features each.**\n",
    "\n",
    "In addition, TensorFlow offers additional conveniences for developers who need to debug and gain introspection into TensorFlow apps. The TensorBoard visualization suite (which will be discussed in the next section of this module) lets you inspect and profile the way your graphs run by way of a simple interactive, web-based dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow alternatives\n",
    "\n",
    "TensorFlow is not the only such library.  Another popular alternative is PyTorch, developed primarily at Facebook (now Meta) which was easier to use than TensorFlow 1 but TensorFlow 2 has more-or-less caught up.\n",
    "\n",
    "Google, where TensorFlow originates from, has more recently also introduced a high-performance numerical library named JAX, which some organizations are using to accelerate their deep learning models.  JAX is not, however, a full-fledged deep learning library like TensorFlow, but rather is used primarily at this time for research into new deep model architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mBAv167fERW",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Computation graphs\n",
    "\n",
    "It is useful for more advanced applications of neural nets to have an understanding of the underlying computational model although you rarely need to deal with it directly (like was necessary with TensorFlow 1).\n",
    "\n",
    "TensorFlow differs from the typical programming library in the sense that its entire architecture is based on a type of computational abstraction known as a **computation graph**. This abstraction (also known as a **dataflow graph**) is used to represent user-defined computations through a network of individual TensorFlow operations (also known as *ops*). This differs from standard programming conventions where one writes procedural instructions to perform calculations. In a TF graph, we use the graph to describe the structure (or **what**) of a computation rather than specifying the step-by-step process (**how**) to perform the calculation.\n",
    "\n",
    "These graphs can be saved in a portable format that allows them to run on a different device than the one they were created on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiVIa3hrfERX"
   },
   "source": [
    "# Using TensorFlow interactively\n",
    "\n",
    "TensorFlow 2 defaults to \"eager\" mode which means we can run individual TF operations and immediately see their results without having to create a computation graph first. We can work with TF much like how we do with NumPy. Let's start with TF variables of type `tf.constant` which we can use to hold static (immutable) values that we want to be a part of our computation.\n",
    "\n",
    "Tensors are simply multi-dimensional arrays similar to NumPy's ndarray type, but have capabilities for distributed computation and/or are specific to neural networks training and use that you won't find in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ek7aA9RSfERX",
    "outputId": "2ee22bb7-6e3f-4257-acac-d9097c83f4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)Metal device set to: Apple M1 Max\n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 15:38:10.934703: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-30 15:38:10.935051: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# We would first import TensorFlow like any other Python library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a tensor holding the scalar value 2\n",
    "c = tf.constant(2)\n",
    "print(c)\n",
    "\n",
    "# Create a tensor containing a matrix\n",
    "m = tf.constant([[1., 2.], [3., 4.]])\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how similar this is to NumPy. We can easily convert the tensors back and forth between NumPy ndarrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "npa = np.array([[1., 2.], [3., 4.]])\n",
    "tft = tf.convert_to_tensor(npa)\n",
    "tft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that tensors also have a shape similar to that of ndarrays.\n",
    "\n",
    "Let's convert tensor back to an ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "npa_again = tf.make_ndarray(tf.make_tensor_proto(tft))\n",
    "print(npa_again)\n",
    "print(type(npa_again))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice tensors using the familiar Python/NumPy slicing syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [5 6]\n",
      " [8 9]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8 , 9]])\n",
    "\n",
    "print(t[0: 1])\n",
    "\n",
    "print(t[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BorzVjMGfERp"
   },
   "source": [
    "## Basic mathematical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors provide a wide variety of built-in operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fp0siDMofERp",
    "outputId": "ac5a7cf9-fa04-4174-df02-737d2289f17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  3  4]\n",
      " [ 5  6  7]\n",
      " [ 8  9 10]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  4  6]\n",
      " [ 8 10 12]\n",
      " [14 16 18]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  4  9]\n",
      " [16 25 36]\n",
      " [49 64 81]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 30  36  42]\n",
      " [ 66  81  96]\n",
      " [102 126 150]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(t)\n",
    "\n",
    "print(t + 1)\n",
    "\n",
    "print(t * 2)\n",
    "\n",
    "print(t * t)\n",
    "\n",
    "print(tf.transpose(t)) # note that this does transpose in-place like NumPy; it creates a new tensor\n",
    "\n",
    "print(t @ t) # the @ sign means matrix multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences from NumPy\n",
    "\n",
    "There are several places where our intuition from using NumPy might mislead us though.\n",
    "\n",
    "Since TensorFlow is typically used for large computations where efficiency is critical, sometimes conveniences that we are used to in Python and NumPy are not available.  This is often because of their performance characteristics or overhead which might go unnoticed but negatively impact model training or prediction speed.\n",
    "\n",
    "For example, TF floating point tensors use 32-bit precision rather than NumPy's 64-bit.  32-bit precision works fine for most neural net applications and are much faster on GPUs, especially on consumer-grade graphics cards.\n",
    "\n",
    "Another example is type conversions (e.g. integer to float, etc.). These must be explicitly handled so it is clear where in a computation they are occuring.  Operations between incompatible types will cause an exception, terminating the computation.  Types can be converted where necessary using tf.cast()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.constant(1), tf.float32) + tf.constant(2.0) # this would throw an exception if the cast were missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "To create a variable tensor, we use tf.Variable() in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1, 2, 3], [4, 5, 6], [7, 8 , 9]])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the value of an entry in a variable tensor, use assign()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, numpy=\n",
       "array([[22,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9]], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 0].assign(22)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other TF data structures\n",
    "\n",
    "TF supports a variety of other special-purpose data structures beyond \"vanilla\" tensors:\n",
    "\n",
    "- tf.SparseTensor: For tensors that are mostly zero so would otherwise waste a lot of space\n",
    "- tf.TensorArray: For working with a list/array of tensors\n",
    "- tf.RaggedTensor: For working with tensors that are unevenly shaped rather than rectangular\n",
    "- tf.string: For storing byte strings (note that they do not handle Unicode)\n",
    "- Sets: TF provides set operations on tensors\n",
    "- Queues: TF provides various types of standard queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen, the usual \"go to\" loss functions for regression and classification are Mean Squared Error (MSE) and Crossentropy Loss respectively.  These are not necessarily the best choices, however, especially if we are building a custom model of some kind.  Researchers have found a large number of alternative loss functions for specific cases.  \n",
    "\n",
    "You can see a list of the Keras loss functions at https://www.tensorflow.org/api_docs/python/tf/keras/losses.  These cover the vast majority of specialized functions you are likely to require.\n",
    "\n",
    "If you do indeed need to create a new loss function that is not covered by the standard set, you can code your own in Python, but for good performance you should use TensorFlow operations as we discussed above, not plain Python or NumPy code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how to code a custom loss function using tensor operations.  This is the popular *Huber Loss* which is useful when training a regression model on noisy data.  It uses squared error for absolute error values less than some threshold (set to its typical value of 1 in this example) and absolute error otherwise. (Huber Loss is actually an existing option in TensorFlow but makes a nice, simple example for our purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and reloading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has the built-in capability to save and reload models.  If the model hasn't been customized, it's as simple as model.save(\"myModel.h5\") to save your model to the file \"myModel.h5\" and model = kera.models.load_model(\"myModel.h5\") to restore it.\n",
    "\n",
    "If you have developed a model that uses custom functions such as the huber_fn above, it is a little more involved but still relatively easy to do.  The save method will store the name of the custom function, but not the function itself.  When you load the model again, you will need to provide a Python dictionary to map the function name to the actual function, which you will need to provide the code for in the notebook you're restoring to:\n",
    "\n",
    "model = keras.models.load_model(\"myModel.h5\"), custom_objects={\"huber_fn\": huber_fn})\n",
    "\n",
    "If you have used subclassing to build a custom model rather than just adding custom functions you will need to implement a get_config() method for the subclass to allow saving and restoring it.  Again, consult the documentation for the version of TensorFlow that you're using for details if you need to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom activation functions, initializers, regularizers, and constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras's built-in functions cover the majority of general use cases. In most cases where a special loss function, regularizer, initializer, etc. are required, they can be implemented as TF function such as w've seen with the Huber Loss.  Here are some examples that reimplement standard functions already present in Keras or TF (again, it would be unusual to need something that isn't already provided):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works the same as tf.nn.softplus(z)\n",
    "def my_softplus(z): \n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "# Works the same as keras.initializers.glorot_normal()\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(.0 / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "# Works the same as keras.regularizers.l1(0.01)\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "# Works the same as keras.constraints.nonneg()\n",
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0.0, tf.zeros_like(weights, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that again we needed to use TF operations (not NumPy ones) because we are performing operations on tensors, not on Numpy objects.  Once we've defined custom functions we can use them in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "layer = keras.layers.Dense(30, activation=my_softplus,\n",
    "                          kernel_initializer=my_glorot_initializer,\n",
    "                          kernel_regularizer=my_l1_regularizer,\n",
    "                          kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with the loss, if your function has hyperparameters that you want saved along with the model, you will need to do a little more work by subclassing the appropriate Keras class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVxz4fxNvRHS"
   },
   "source": [
    "**End of Module**\n",
    "\n",
    "You have reached the end of this module.\n",
    "\n",
    "If you have any questions, please reach out to your peers using the discussion boards. If you\n",
    "and your peers are unable to come to a suitable conclusion, do not hesitate to reach out to\n",
    "your instructor on the designated discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Géron, A. (2017). Chapter 12: Custom Models and Training with TensorFlow in *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* (2nd ed.). O’Reilly Media. https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\n",
    "\n",
    "\n",
    "- TensorFlow documentation and tutorials: https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "REwVzdpHfESo",
    "gJQE1lPDfESv",
    "0KRNrsH-fESv",
    "JUa_3pX8fESy"
   ],
   "name": "Module09_Part1_edited_by_ML_MC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
