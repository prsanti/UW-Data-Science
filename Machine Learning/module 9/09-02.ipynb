{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWVS9tj6T854",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Module 9 Part 2: Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module consists of 2 parts:\n",
    "\n",
    "- **Part 1** - Focuses on the fundamentals (including a custom implementation of a feedforward neural network from scratch using NumPy)\n",
    "\n",
    "- **Part 2** - Focuses on using packages like TensorFlow and Keras to rapidly develop and train deep neural network models\n",
    "\n",
    "Each part is provided in a separate notebook file. It is recommended that you follow the order of the notebooks.\n",
    "\n",
    "In the last section, we built a custom neural network model from scratch using NumPy, which was a lot of hard work. Fortunately, we can leverage the power of TensorFlow and Keras to build these models in a much easier fashion. \n",
    "\n",
    "We will build a model using Keras, a high level API that is built on top of TensorFlow which can greatly simplify the model development and testing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Vlr3k-kT855"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\">\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Module-9-Part-2:-Introduction-to-Keras\" data-toc-modified-id=\"Module-9-Part-2:-Introduction-to-Keras\">Module 9 Part 2: Introduction to Keras</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Table-of-Contents\" data-toc-modified-id=\"Table-of-Contents\">Table of Contents</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Neural-Nets-with-Keras\" data-toc-modified-id=\"Neural-Nets-with-Keras\">Neural Nets with Keras</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#What-is-TensorFlow?\" data-toc-modified-id=\"What-is-TensorFlow?\">What is TensorFlow?</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#TensorFlow-Setup\" data-toc-modified-id=\"TensorFlow-Setup\">TensorFlow Setup</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Load-the-Dataset\" data-toc-modified-id=\"Load-the-Dataset\">Load the Dataset</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Keras\" data-toc-modified-id=\"Keras\">Keras</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Sequential-Models\" data-toc-modified-id=\"Sequential-Models\">Sequential Models</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Functional-API\" data-toc-modified-id=\"Functional-API\">Functional API</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Compile-and-Train\" data-toc-modified-id=\"Compile-and-Train\">Compile and Train</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Evaluate-and-Predict\" data-toc-modified-id=\"Evaluate-and-Predict\">Evaluate and Predict</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#Basic-Fine-Tuning-of-Neural-Networks\" data-toc-modified-id=\"Basic-Fine-Tuning-of-Neural-Networks\">Basic Fine-Tuning of Neural Networks</a></span>\n",
    "<ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Choosing-the-Number-of-Hidden-Layers\" data-toc-modified-id=\"Choosing-the-Number-of-Hidden-Layers\">Choosing the Number of Hidden Layers</a></span>\n",
    "</li>\n",
    "<li><span><a href=\"#Choosing-the-Number-of-Neurons\" data-toc-modified-id=\"Choosing-the-Number-of-Neurons\">Choosing the Number of Neurons</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li><span><a href=\"#References\" data-toc-modified-id=\"References\">References</a></span>\n",
    "</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSHyo8fUT856"
   },
   "source": [
    "# Neural Nets with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is TensorFlow?\n",
    "\n",
    "Machine learning (ML) is a complex discipline. That said, building and implementing ML models is now significantly less daunting now than it used to be, largely thanks to sophisticated machine learning frameworks such as Scikit-learn (sklearn). While sklearn has become extremely popular for more traditional machine learning techniques, **[TensorFlow](https://www.tensorflow.org/) and [PyTorch](https://pytorch.org/) have become the dominant frameworks for the development of Neural Networks.** Both are great choices for anyone looking to develop an expertise in Neural Networks and Deep Learning. We will focus on TF in modules 9, 10 and 11 but most of what you learn can be used with PyTorch by looking up the equivalent PyTorch syntax.\n",
    "\n",
    "TensorFlow is an open-source programming library reserved for high-demand numerical computation. It was originally developed by members of the Google Brain team for internal Google use, but later released under the *Apache 2.0 open-source license* near the end of 2015. It is an excellent choice for large-scale machine learning applications as it was built with highly optimized C++ code and a computational graph architecture, allowing for efficient parallelization (which is essential for training complex with lots of data). As a result, TensorFlow has made its way to become the tool of choice for many machine learning and deep learning practitioners. It also serves as the foundation for many popular simplified neural network APIs such as [Keras](https://keras.io/).\n",
    " \n",
    "TensorFlow can train and run deep neural networks for image recognition, object detection, machine translation, and many other kinds of sophisticated and complicated deep learning models. Perhaps most importantly, TensorFlow supports production prediction at scale, with the same models used for training.\n",
    "\n",
    "In the balance of this and the next we will be using Keras with TensorFlw to easily build a neural net. In Module 11 we will look at how TensorFlow works more generally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Setup\n",
    "\n",
    "TensorFlow (TF) is available as a Python library (which is the implementation we will be using here). It must be installed into your Python package directory before it can be used. This can easily be done using the appropriate Python package installer (i.e. `pip`, `conda`). For more details on configuring TensorFlow onto your machine, please review the official documentation on installation: [**install TensorFlow**](https://www.tensorflow.org/install).\n",
    "\n",
    "Note that we will not need to use GPUs (graphics processing units) or TPUs (tensor processing units) in this course. You also should not have to configure a container (i.e. Docker) to run TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNR6naYwT857"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F28Wxt2VT858"
   },
   "source": [
    "Before we dig into model development, we will load our dataset. We will be working with the **Forest CoverType** dataset, available through sklearn's `datasets` API. We have printed the description below. However, for our purposes, all you really need to know is that it is a multi-class problem with 7 classes and 54 features. We will load, normalize, and split the data into training and test sets below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1200,
     "status": "ok",
     "timestamp": 1565547694816,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "kud4fQ2AT858",
    "outputId": "5a1020e1-4cbc-4f82-ea1c-b0acc7c3eb53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _covtype_dataset:\n",
      "\n",
      "Forest covertypes\n",
      "-----------------\n",
      "\n",
      "The samples in this dataset correspond to 30Ã—30m patches of forest in the US,\n",
      "collected for the task of predicting each patch's cover type,\n",
      "i.e. the dominant species of tree.\n",
      "There are seven covertypes, making this a multiclass classification problem.\n",
      "Each sample has 54 features, described on the\n",
      "`dataset's homepage <https://archive.ics.uci.edu/ml/datasets/Covertype>`__.\n",
      "Some of the features are boolean indicators,\n",
      "while others are discrete or continuous measurements.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ============\n",
      "    Classes                        7\n",
      "    Samples total             581012\n",
      "    Dimensionality                54\n",
      "    Features                     int\n",
      "    =================   ============\n",
      "\n",
      ":func:`sklearn.datasets.fetch_covtype` will load the covertype dataset;\n",
      "it returns a dictionary-like 'Bunch' object\n",
      "with the feature matrix in the ``data`` member\n",
      "and the target values in ``target``. If optional argument 'as_frame' is\n",
      "set to 'True', it will return ``data`` and ``target`` as pandas\n",
      "data frame, and there will be an additional member ``frame`` as well.\n",
      "The dataset will be downloaded from the web if necessary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "data = datasets.fetch_covtype()\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2552,
     "status": "ok",
     "timestamp": 1565547696177,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "YwptICzUT86A",
    "outputId": "4340cca3-d207-4a08-8efd-225805905bbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (435759, 54)\n",
      "X_test shape: (145253, 54)\n",
      "y_train shape: (435759, 7)\n",
      "y_test shape: (145253, 7)\n",
      "n_inputs: 54\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "X_raw = data['data']\n",
    "X_raw_scaled = StandardScaler().fit_transform(X_raw)\n",
    "y_raw = data['target']\n",
    "y_raw_oh = OneHotEncoder(categories='auto', sparse=False).fit_transform(y_raw.reshape(-1,1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw_scaled, y_raw_oh, shuffle=True)\n",
    "n_classes = len(np.unique(y_raw))\n",
    "n_inputs = X_train.shape[1]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"n_inputs:\", n_inputs)\n",
    "print(\"n_classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxacdR9ET86f"
   },
   "source": [
    "## Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NxLIy6fxT86g"
   },
   "source": [
    "**Keras** is a high-level API used for quickly developing and testing neural network models, and can leverage lower level graph-based architectures on the backend (e.g. TensorFlow or Theano). To clarify, it is important to understand that most deep learning frameworks operate at 2 levels of abstraction:\n",
    "\n",
    "1. **Lower Level:** This is where frameworks like Tensorflow, MXNet, Theano, and PyTorch sit. This is the level where mathematical operations like matrix multiplication and convolutional operations are implemented.<br><br>\n",
    "\n",
    "2. **Higher Level:** This is where frameworks like Keras sit. At this level, the lower level functions are used to implement neural network abstractions such as layers and models. Generally, at this level other helpful APIs like model saving and model training are also implemented.\n",
    "\n",
    "As noted, Keras can be used with multiple backends. In fact, if you install Keras and import it as is, you should automatically get a message stating that it is running Keras \"Using TensorFlow backend\" (this will only display the first time you import the Keras module). If you plan to actively maintain framework-agnostic code (e.g. if you want to run your models using Theano or PyTorch as well), using Keras-only code is your only choice.\n",
    "\n",
    "That said, the implementation we will be working with is called `tf.keras`, which is an implementation of Keras **implemented exclusively with/for TensorFlow**. Although `tf.keras` and `Keras` have separate code bases, they are tightly coupled. With updated documentation and programmer guides, `tf.keras` is clearly the high level API to look for when building neural networks with TensorFlow. As a rule of thumb, you should try not to mix base `tf` code with `tf.keras` code. Most things in TensorFlow will have a corresponding `tf.keras` implementation (though the level of customization may be lower). So, unless you need something very custom and specific, try to stick with the `tf.keras` code\n",
    "\n",
    "**NOTE**: When we refer to Keras henceforth, we will be referring strictly to `tf.keras` (though much of the implementation would look the same either way)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLgqFaFwT86h"
   },
   "source": [
    "With Keras there are two main methods for building models:\n",
    "\n",
    "1. **Sequential API:** Which allows you to stack layers in a linear fashion, one after the other. This doesn't allow for flexible model architectures, but is great for building simple models very quickly.<br><br>\n",
    "\n",
    "2. **Functional API**: Which allows for more flexibility in your model architecture (multiple inputs/outputs, reusing parameters, etc). This requires a bit more finesse, but can be very useful for advanced and complex architectures.\n",
    "\n",
    "We will go through both of these strategies now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82570,
     "status": "ok",
     "timestamp": 1565547776271,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "zKH015bxT86i",
    "outputId": "87aee4ac-4813-45de-f501-d62bdddec245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Loading tf.keras (TensorFlow specific implementation of Keras) \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import tensorflow.keras.backend as K\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6xAY26AT86l"
   },
   "source": [
    "## Sequential Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9vLZVdET86l"
   },
   "source": [
    "With the `Sequential` method, you assemble your model one layer at a time. To build a simple, fully-connected network we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82563,
     "status": "ok",
     "timestamp": 1565547776271,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "OVrb0YbGT86m",
    "outputId": "3fa44b23-6443-46ff-cb2c-be39022a4502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 09:31:59.704769: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-01 09:31:59.704957: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 3,047\n",
      "Trainable params: 3,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Clear the session (similar to tf.reset_default_graph)\n",
    "K.clear_session()\n",
    "\n",
    "# Initialize model\n",
    "model = keras.Sequential()\n",
    "# Adds a densely-connected layer with 32 units to the model. Specify the input_shape for the first layer!\n",
    "model.add(keras.layers.Dense(units=32, activation='relu', input_shape=(54,)))\n",
    "# Add another:\n",
    "model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(keras.layers.Dense(units=7, activation='softmax'))\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38JijGEBT86r"
   },
   "source": [
    "There are a few main components to explain here:\n",
    "\n",
    "- `tf.keras.Sequential()`: This initializes our model. You can think of this as setting up a blank graph, to which we will simply add layers one at a time.\n",
    "\n",
    "\n",
    "- `model.add()`: Once we have initialized our model, we can simply add layers to it with the `.add` method, through which we pass the layer type we want to add.\n",
    "\n",
    "\n",
    "- `keras.layers.Dense()`: We use this function to tell `model.add()` that we'd like to add a fully-connected dense layer to our model. In this function we specify the number of neurons (`inputs`), and the activation function. Note that the first time we add a layer, we must specify the `input_shape` so the model knows what to expect for our `X` values.\n",
    "\n",
    "\n",
    "- `model.summary()`: This method gives us a quick and simple summary of our model layers, with the output layer type, output shape, and number of parameters in each layer.\n",
    "\n",
    "We use `tf.keras.layers.Dense` to sequentially add layers to the model. `tf.keras.layers.Dense` is a \"tensorflow-keras\" layer while `tf.layers.Dense` is a TensorFlow \"native layer\". However, the arguments for both are almost identical (again, we won't go into the details of most of these arguments for now, as you will only need the `units`, `activation`, `use_bias`, and `kernel_initializer` for our purposes).\n",
    "\n",
    "\n",
    "**`tf.layers.Dense` arguments:**\n",
    "- `(['units', 'activation=None', 'use_bias=True', 'kernel_initializer=None', 'bias_initializer=<tensorflow.python.ops.init_ops.Zeros object at 0x0000014437E068D0>', 'kernel_regularizer=None', 'bias_regularizer=None', 'activity_regularizer=None', 'kernel_constraint=None', 'bias_constraint=None', 'trainable=True', 'name=None', '**kwargs'])`\n",
    "\n",
    "**`tf.keras.layers.Dense` arguments:**\n",
    "- `(['units', 'activation=None', 'use_bias=True', \"kernel_initializer='glorot_uniform'\", \"bias_initializer='zeros'\", 'kernel_regularizer=None', 'bias_regularizer=None', 'activity_regularizer=None', 'kernel_constraint=None', 'bias_constraint=None', '**kwargs'])`\n",
    ")\n",
    "\n",
    "The `tf.layers` module is Tensorflow's attempt at creating a Keras-like API (as mentioned, Keras can be run with various neural net frameworks other than TensorFlow), whereas `tf.keras.layers` is simply a compatibility wrapper that leverages the underlying TensorFlow architecture. In fact, most of the `tf.keras.layers` implementation refers back to `tf.layers`, for example `tf.keras.layers.Dense` inherits the [core TensorFlow implementation](https://github.com/tensorflow/tensorflow/blob/23c218785eac5bfe737eec4f8081fd0ef8e0684d/tensorflow/python/keras/_impl/keras/layers/core.py#L728).\n",
    "\n",
    "\n",
    "**Note that you cannot use a native TensorFlow layer directly within a Keras model, as it will be missing certain attributes required by the Keras API &mdash; give it a try above, and you will get some funky errors!** However, it is possible to use a TensorFlow native layer if it is wrapped within a `tf.keras` [Lambda layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda). It is recommended that you stick to one or the other as mixing them can create some unexpected compatibility issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uAREZjyT86r"
   },
   "source": [
    "We can also build our model by passing in a list of layers into the actual `tf.keras.Sequential` class. From here we can continue to add layers as we please, just as we did above. We have also added some code to explore the \"model configuration\" using the `.get_config()` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82845,
     "status": "ok",
     "timestamp": 1565547776559,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "JaOvWjJGT86s",
    "outputId": "80be4ab6-834d-4d63-d005-081ce662f37f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 3,047\n",
      "Trainable params: 3,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = keras.Sequential([\n",
    "        # Adds a densely-connected layer with 64 units to the model:\n",
    "        keras.layers.Dense(32, activation='relu', input_shape=(54,)),\n",
    "        # Add another:\n",
    "        keras.layers.Dense(32, activation='relu')])\n",
    "# Add a final softmax layer\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82839,
     "status": "ok",
     "timestamp": 1565547776560,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "8QZcCeZCT86t",
    "outputId": "23997548-23b2-4a81-b79f-ea1f5cf1984b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "sequential \n",
      "\n",
      "layers\n",
      "[{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 54), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'dense_input'}}, {'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'batch_input_shape': (None, 54), 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 7, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check out model config\n",
    "for key, val in model.get_config().items():\n",
    "    print(key)\n",
    "    print(val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjZMSDigT86w"
   },
   "source": [
    "## Functional API\n",
    "\n",
    "The `tf.keras.Sequential` model is a simple stack of layers that cannot represent arbitrary models. However, we often want to construct models with more complex topologies, including:\n",
    " \n",
    "- Multi-input models\n",
    "- Multi-output models\n",
    "- Models with shared layers (the same layer called several times)\n",
    "- Models with non-sequential data flows (e.g. residual connections)\n",
    "\n",
    "For these kinds of models, we use the [Keras functional API](https://keras.io/getting-started/functional-api-guide/). The development process is slightly different, but most of the functionality will remain the same. Let's reconstruct our simple classification model using the functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82832,
     "status": "ok",
     "timestamp": 1565547776560,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "0ehAjj33T86x",
    "outputId": "089a1273-d3b1-441b-a057-eda626722ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_functional_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X_Inputs (InputLayer)        [(None, 54)]              0         \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 32)                1760      \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "Y_Outputs (Dense)            (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 3,047\n",
      "Trainable params: 3,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Declare input layer\n",
    "X = keras.Input(shape=(54,), name='X_Inputs')  # Returns a placeholder tensor\n",
    "\n",
    "# Feed layers into one another sequentially\n",
    "L1 = keras.layers.Dense(32, activation='relu', kernel_initializer='random_uniform', name='Layer_1')(inputs=X)\n",
    "L2 = keras.layers.Dense(32, activation='relu', kernel_initializer='random_uniform', name='Layer_2')(inputs=L1)\n",
    "y_proba = keras.layers.Dense(7, activation='softmax', kernel_initializer='random_uniform', name='Y_Outputs')(inputs=L2)\n",
    "\n",
    "# Feed X and y_proba into keras.Model class\n",
    "model = tf.keras.Model(inputs=[X], outputs=[y_proba], name='my_functional_model')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82826,
     "status": "ok",
     "timestamp": 1565547776561,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "qp1ta1xwT86y",
    "outputId": "882c07e4-fa72-4f68-ef35-61ea996f3c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "my_functional_model \n",
      "\n",
      "layers\n",
      "[{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 54), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'X_Inputs'}, 'name': 'X_Inputs', 'inbound_nodes': []}, {'class_name': 'Dense', 'config': {'name': 'Layer_1', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'name': 'Layer_1', 'inbound_nodes': [[['X_Inputs', 0, 0, {}]]]}, {'class_name': 'Dense', 'config': {'name': 'Layer_2', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'name': 'Layer_2', 'inbound_nodes': [[['Layer_1', 0, 0, {}]]]}, {'class_name': 'Dense', 'config': {'name': 'Y_Outputs', 'trainable': True, 'dtype': 'float32', 'units': 7, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'name': 'Y_Outputs', 'inbound_nodes': [[['Layer_2', 0, 0, {}]]]}] \n",
      "\n",
      "input_layers\n",
      "[['X_Inputs', 0, 0]] \n",
      "\n",
      "output_layers\n",
      "[['Y_Outputs', 0, 0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check out model config\n",
    "for key, val in model.get_config().items():\n",
    "    print(key)\n",
    "    print(val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niWBQ8rWT860"
   },
   "source": [
    "There are a couple of major differences to take note of here:\n",
    "\n",
    "1. Instead of passing in an `input_shape` argument into our first layer as we did with the Sequential model, we instead must define a `tf.keras.Input` class, which is then then fed into the `tf.keras.Model` class. Setting up our model this way allows us to specify multiple inputs and outputs, and gives us more flexibility when designing our model structures. Note that we feed in `y_proba` (the last layer of our model) to the `outputs` argument of `tf.keras.Model`.<br><br>\n",
    "\n",
    "2. Just as we did with the `tf.layers` model in the TensorFlow implementation section, when using the functional API we have to sequentially pass the layers into one another. In this way, the functional API combines the flexibility of TensorFlow, with the ease of development of the Keras high level API. \n",
    "\n",
    "Once we have defined our layers and passed the input and output tensors (or rather, the variables that reference the tensors) into a `tf.keras.Model` class, everything else stays the same as with the Sequential API. We can call the usual methods `.fit`, `.evaluate`, and `.predict` (as we will discuss shortly) on all of the above `tf.keras` models.\n",
    "\n",
    "**NOTE**: The `.get_config()` output is slightly different for functional API models. This is because the flexible architecture requires a slightly more complex configuration. You are encouraged to compare the config output above with that of the previous model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVctgMlgT862"
   },
   "source": [
    "## Compile and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVgt-tn-T862"
   },
   "source": [
    "After the model is constructed, we can configure its learning process by calling the `tf.keras.Model.compile` method. The compile method takes three important arguments:\n",
    "\n",
    "1. **`optimizer`**: This object specifies the training procedure. You can pass it optimizer instances from the `tf.keras.optimizers` module, such as `tf.keras.optimizers.SGD` (Stochastic Gradient Descent), `tf.keras.optimizers.RMSprop`, or `tf.keras.optimizers.Adam`. Note that you must call these optimizers first, passing in the required parameters (see below for an example).<br><br>\n",
    "\n",
    "2. **`loss`**: The function to minimize during optimization. Common choices include mean square error (MSE), `categorical_crossentropy`, and `binary_crossentropy`. Loss functions are specified by name (string) or by passing a callable object from the `tf.keras.losses` module.<br><br>\n",
    "\n",
    "3. **`metrics`**: Used to monitor training. These are string names or callables from the `tf.keras.metrics` module.\n",
    "\n",
    "The `compile` method essentially sets up our model so that it is ready for training. In the next cell, we create a model and compile it with a gradient descent optimizer using categorical cross-entropy as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82817,
     "status": "ok",
     "timestamp": 1565547776561,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "OHO-LVikT864",
    "outputId": "3bd27bb4-c6a5-497d-e981-14d97862a6b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 54) dtype=float32 (created by layer 'dense_input')>]\n",
      "[<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'dense_2')>]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 3,047\n",
      "Trainable params: 3,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/wumpus/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = keras.Sequential([keras.layers.Dense(32, activation='relu', input_shape=(54,)),\n",
    "                             keras.layers.Dense(32, activation='relu'),\n",
    "                             keras.layers.Dense(7, activation='softmax')]) # 7 classes \n",
    "\n",
    "# Compile the model using Gradient Descent\n",
    "optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.inputs)\n",
    "print(model.outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RusQt0E3T866"
   },
   "source": [
    "Training (or fitting) a model with Keras is extremely simple, and very much resembles the simple `.fit` methodology used by Scikit-learn. To fit a Keras model, all you have to do is call `tf.keras.Model.fit`, which takes in three important arguments:\n",
    "\n",
    "1. **`epochs`**: An epoch is one iteration over the entire input dataset.<br><br>\n",
    "\n",
    "2. **`batch_size`**: When passed NumPy data, the model slices the data into smaller batches and iterates over these batches during training. This integer specifies the size of each batch. Be aware that the last batch may be smaller if the total number of samples is not divisible by the batch size.<br><br>\n",
    "\n",
    "3. **`validation_data`**: When prototyping a model, you want to be able to easily monitor its performance on some validation data. Passing this argument &mdash; a tuple of inputs and labels &mdash; allows the model to display the loss and metrics in inference mode for the passed data, at the end of each epoch.\n",
    "\n",
    "Let's train with a batch size of 3,200 for 30 epochs.\n",
    "\n",
    "**NOTE**: Keras produces a progress bar to track the model training. You can change how much training information you want to see with the `verbose` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 157646,
     "status": "ok",
     "timestamp": 1565547851398,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "br6dNEIaT867",
    "outputId": "8d0ef63f-ed68-439b-ae5f-2f2b9fb5e003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 3,047\n",
      "Trainable params: 3,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 09:32:01.204968: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-01 09:32:01.205418: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-01 09:32:01.294161: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "137/137 [==============================] - ETA: 0s - loss: 1.8034 - accuracy: 0.4831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 09:32:04.354615: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 3s 12ms/step - loss: 1.8034 - accuracy: 0.4831 - val_loss: 1.6773 - val_accuracy: 0.4866\n",
      "Epoch 2/50\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 1.5857 - accuracy: 0.4879 - val_loss: 1.5049 - val_accuracy: 0.4866\n",
      "Epoch 3/50\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 1.4468 - accuracy: 0.4879 - val_loss: 1.3956 - val_accuracy: 0.4866\n",
      "Epoch 4/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.3585 - accuracy: 0.4879 - val_loss: 1.3255 - val_accuracy: 0.4866\n",
      "Epoch 5/50\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 1.3016 - accuracy: 0.4879 - val_loss: 1.2799 - val_accuracy: 0.4866\n",
      "Epoch 6/50\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 1.2639 - accuracy: 0.4879 - val_loss: 1.2490 - val_accuracy: 0.4866\n",
      "Epoch 7/50\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 1.2377 - accuracy: 0.4879 - val_loss: 1.2264 - val_accuracy: 0.4866\n",
      "Epoch 8/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.2172 - accuracy: 0.4879 - val_loss: 1.2070 - val_accuracy: 0.4866\n",
      "Epoch 9/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.1975 - accuracy: 0.4879 - val_loss: 1.1862 - val_accuracy: 0.4866\n",
      "Epoch 10/50\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 1.1743 - accuracy: 0.4879 - val_loss: 1.1609 - val_accuracy: 0.4866\n",
      "Epoch 11/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.1504 - accuracy: 0.4879 - val_loss: 1.1401 - val_accuracy: 0.4866\n",
      "Epoch 12/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.1308 - accuracy: 0.4879 - val_loss: 1.1208 - val_accuracy: 0.4866\n",
      "Epoch 13/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.1111 - accuracy: 0.4879 - val_loss: 1.1009 - val_accuracy: 0.4866\n",
      "Epoch 14/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.0907 - accuracy: 0.4879 - val_loss: 1.0796 - val_accuracy: 0.4866\n",
      "Epoch 15/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.0672 - accuracy: 0.4879 - val_loss: 1.0535 - val_accuracy: 0.4866\n",
      "Epoch 16/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.0378 - accuracy: 0.4880 - val_loss: 1.0209 - val_accuracy: 0.4884\n",
      "Epoch 17/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 1.0037 - accuracy: 0.5112 - val_loss: 0.9874 - val_accuracy: 0.5201\n",
      "Epoch 18/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.9740 - accuracy: 0.5302 - val_loss: 0.9623 - val_accuracy: 0.5356\n",
      "Epoch 19/50\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.9522 - accuracy: 0.5523 - val_loss: 0.9429 - val_accuracy: 0.5702\n",
      "Epoch 20/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.9333 - accuracy: 0.5892 - val_loss: 0.9241 - val_accuracy: 0.6018\n",
      "Epoch 21/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.9137 - accuracy: 0.6125 - val_loss: 0.9038 - val_accuracy: 0.6216\n",
      "Epoch 22/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.8923 - accuracy: 0.6348 - val_loss: 0.8815 - val_accuracy: 0.6492\n",
      "Epoch 23/50\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.8693 - accuracy: 0.6640 - val_loss: 0.8582 - val_accuracy: 0.6728\n",
      "Epoch 24/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.8462 - accuracy: 0.6771 - val_loss: 0.8358 - val_accuracy: 0.6797\n",
      "Epoch 25/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.8250 - accuracy: 0.6822 - val_loss: 0.8160 - val_accuracy: 0.6852\n",
      "Epoch 26/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.8068 - accuracy: 0.6874 - val_loss: 0.7993 - val_accuracy: 0.6903\n",
      "Epoch 27/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7916 - accuracy: 0.6925 - val_loss: 0.7854 - val_accuracy: 0.6942\n",
      "Epoch 28/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7788 - accuracy: 0.6962 - val_loss: 0.7737 - val_accuracy: 0.6973\n",
      "Epoch 29/50\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.7678 - accuracy: 0.6992 - val_loss: 0.7633 - val_accuracy: 0.6998\n",
      "Epoch 30/50\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.7579 - accuracy: 0.7019 - val_loss: 0.7539 - val_accuracy: 0.7030\n",
      "Epoch 31/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7488 - accuracy: 0.7041 - val_loss: 0.7451 - val_accuracy: 0.7046\n",
      "Epoch 32/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7404 - accuracy: 0.7055 - val_loss: 0.7370 - val_accuracy: 0.7057\n",
      "Epoch 33/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7326 - accuracy: 0.7065 - val_loss: 0.7295 - val_accuracy: 0.7068\n",
      "Epoch 34/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7254 - accuracy: 0.7075 - val_loss: 0.7226 - val_accuracy: 0.7079\n",
      "Epoch 35/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7189 - accuracy: 0.7086 - val_loss: 0.7165 - val_accuracy: 0.7087\n",
      "Epoch 36/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7134 - accuracy: 0.7092 - val_loss: 0.7114 - val_accuracy: 0.7092\n",
      "Epoch 37/50\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.7087 - accuracy: 0.7100 - val_loss: 0.7072 - val_accuracy: 0.7101\n",
      "Epoch 38/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7048 - accuracy: 0.7110 - val_loss: 0.7037 - val_accuracy: 0.7114\n",
      "Epoch 39/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.7016 - accuracy: 0.7120 - val_loss: 0.7007 - val_accuracy: 0.7121\n",
      "Epoch 40/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6988 - accuracy: 0.7132 - val_loss: 0.6981 - val_accuracy: 0.7129\n",
      "Epoch 41/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6964 - accuracy: 0.7143 - val_loss: 0.6958 - val_accuracy: 0.7142\n",
      "Epoch 42/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6942 - accuracy: 0.7157 - val_loss: 0.6937 - val_accuracy: 0.7159\n",
      "Epoch 43/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6921 - accuracy: 0.7179 - val_loss: 0.6916 - val_accuracy: 0.7190\n",
      "Epoch 44/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6901 - accuracy: 0.7204 - val_loss: 0.6897 - val_accuracy: 0.7200\n",
      "Epoch 45/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6882 - accuracy: 0.7211 - val_loss: 0.6878 - val_accuracy: 0.7208\n",
      "Epoch 46/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6864 - accuracy: 0.7219 - val_loss: 0.6861 - val_accuracy: 0.7219\n",
      "Epoch 47/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6847 - accuracy: 0.7230 - val_loss: 0.6844 - val_accuracy: 0.7232\n",
      "Epoch 48/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6831 - accuracy: 0.7243 - val_loss: 0.6829 - val_accuracy: 0.7249\n",
      "Epoch 49/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6816 - accuracy: 0.7259 - val_loss: 0.6814 - val_accuracy: 0.7264\n",
      "Epoch 50/50\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6802 - accuracy: 0.7269 - val_loss: 0.6799 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aa48cd90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = keras.Sequential([keras.layers.Dense(32, activation='relu', input_shape=(54,), kernel_initializer='random_uniform'),\n",
    "                             keras.layers.Dense(32, activation='relu', kernel_initializer='random_uniform'),\n",
    "                             keras.layers.Dense(7, activation='softmax',kernel_initializer='random_uniform')])\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=3200, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kn7kG1HgT869"
   },
   "source": [
    "There's one last thing to mention here. You may have noticed that at the end of training Keras returned a `keras.callbacks.History` object. This essentially stores results from our training process. It can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 157640,
     "status": "ok",
     "timestamp": 1565547851399,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "CkPEofgwT86-",
    "outputId": "285145c1-1b16-4fb0-a45d-2b482f9bd348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results  = model.history.history\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ny8GCIrGT86_"
   },
   "source": [
    "As you can see, the model automatically stores the loss and accuracy values for both the training and test sets at every epoch. We can also ask Keras to store more metrics when we compile the model with the `metrics` argument. Let's plot the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 157817,
     "status": "ok",
     "timestamp": 1565547851583,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "SmuetxITT87A",
    "outputId": "dc10e510-bb11-4e57-818f-aa7fbf542e56"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwZklEQVR4nO3dd3hUZdrH8e+dOuk9QAgQQiihl4CwiIBYEBQFRVFQQdQF27quvqC7irrrru4isqjoooC9IAqigqAIBqR3QpFeQihJIL0nz/vHDIiahAQyDMm5P9eVi8yZM2fuIyO/OedpYoxBKaWUdbm5ugCllFKupUGglFIWp0GglFIWp0GglFIWp0GglFIW5+HqAqorPDzcxMTEuLoMpZSqVdavX59mjIko77laFwQxMTGsW7fO1WUopVStIiIHK3pObw0ppZTFaRAopZTFaRAopZTF1bo2AqXUxVdcXExycjIFBQWuLkWdg81mIzo6Gk9Pzyq/RoNAKXVOycnJBAQEEBMTg4i4uhxVAWMM6enpJCcn07Rp0yq/Tm8NKaXOqaCggLCwMA2BS5yIEBYWVu0rN6cFgYjMEJETIpJUwfNBIvKViGwWkW0iMspZtSilLpyGQO1wPn9PzrwieAfoX8nzDwLbjTEdgD7AyyLi5axifj6WzYsLdpJdUOyst1BKqVrJaUFgjEkETla2CxAg9vjyd+xb4qx6Dp/M480f97L7RI6z3kIp5SQZGRlMnTr1vF47YMAAMjIyKt3nmWee4fvvvz+v4/9WTEwMaWlpNXKsi8WVbQSvAfFACrAV+JMxpqy8HUXkfhFZJyLrUlNTz+vN4iL9AdhzXINAqdqmsiAoKan8++P8+fMJDg6udJ/nn3+eq6666nzLq/VcGQTXApuAKKAj8JqIBJa3ozFmmjEmwRiTEBFR7lQZ59Qo1BcvDzf2pGoQKFXbjB8/nr1799KxY0eeeOIJli5dSq9evRg0aBCtW7cG4KabbqJLly60adOGadOmnXnt6W/oBw4cID4+nvvuu482bdpwzTXXkJ+fD8DIkSOZPXv2mf0nTJhA586dadeuHTt37gQgNTWVq6++mjZt2nDvvffSpEmTc37znzRpEm3btqVt27ZMnjwZgNzcXAYOHEiHDh1o27Ytn3766ZlzbN26Ne3bt+fxxx+v0f9+5+LK7qOjgBeNfa3MPSKyH2gFrHHGm7m7CbHhfuw+nu2MwytlGc99tY3tKVk1eszWUYFMuKFNhc+/+OKLJCUlsWnTJgCWLl3Khg0bSEpKOtNNcsaMGYSGhpKfn0/Xrl25+eabCQsL+9Vxdu/ezccff8xbb73Frbfeyueff86IESN+937h4eFs2LCBqVOnMnHiRN5++22ee+45rrzySp588km+/fZbpk+fXuk5rV+/npkzZ7J69WqMMVx22WX07t2bffv2ERUVxTfffANAZmYm6enpzJkzh507dyIi57yVVdNceUVwCOgHICL1gJbAPme+YfN6AXpFoFQd0a1bt1/1lZ8yZQodOnSge/fuHD58mN27d//uNU2bNqVjx44AdOnShQMHDpR77CFDhvxun+XLlzNs2DAA+vfvT0hISKX1LV++nMGDB+Pn54e/vz9Dhgxh2bJltGvXju+++45x48axbNkygoKCCAoKwmazMXr0aL744gt8fX2r+V/jwjjtikBEPsbeGyhcRJKBCYAngDHmTeDvwDsishUQYJwxxqktLHER/ny9JYX8olJ8vNyd+VZK1VmVfXO/mPz8/M78vnTpUr7//ntWrlyJr68vffr0Kbcvvbe395nf3d3dz9waqmg/d3f3c7ZBVFeLFi3YsGED8+fP529/+xv9+vXjmWeeYc2aNSxevJjZs2fz2muv8cMPP9To+1bGaUFgjLn9HM+nANc46/3L07yeP8bA3tQc2jYMuphvrZS6AAEBAWRnV3xbNzMzk5CQEHx9fdm5cyerVq2q8Rp69uzJrFmzGDduHIsWLeLUqVOV7t+rVy9GjhzJ+PHjMcYwZ84c3n//fVJSUggNDWXEiBEEBwfz9ttvk5OTQ15eHgMGDKBnz57ExsbWeP2VsdQUE2d6Dp3QIFCqNgkLC6Nnz560bduW6667joEDB/7q+f79+/Pmm28SHx9Py5Yt6d69e43XMGHCBG6//Xbef/99evToQf369QkICKhw/86dOzNy5Ei6desGwL333kunTp1YuHAhTzzxBG5ubnh6evLGG2+QnZ3NjTfeSEFBAcYYJk2aVOP1V0bsbbW1R0JCgjnfhWmKSsqIf+ZbxvZuxuPXtqzhypSqu3bs2EF8fLyry3CpwsJC3N3d8fDwYOXKlYwdO/ZM4/Wlpry/LxFZb4xJKG9/S10ReHm40STMlz06qEwpVU2HDh3i1ltvpaysDC8vL9566y1Xl1RjLBUEAM0j/dl9QruQKqWqp3nz5mzcuNHVZTiF5WYfjYv052B6HkUl5Q5iVkopy7FcEDSPDKCkzHAwPdfVpSil1CXBckFwds8hpZRSFgyCZhH+iKCzkCqllIPlgsDHy52GwT56RaBUHefvb7/6T0lJ4ZZbbil3nz59+nCu7uiTJ08mLy/vzOOqTGtdFc8++ywTJ0684OPUBMsFAZzuOaRBoJQVREVFnZlZ9Hz8NgiqMq11bWPJIIiL9Gdfag6lZbVrMJ1SVjV+/Hhef/31M49Pf5vOycmhX79+Z6aM/vLLL3/32gMHDtC2bVsA8vPzGTZsGPHx8QwePPhXcw2NHTuWhIQE2rRpw4QJEwD7RHYpKSn07duXvn37Ar9eeKa8aaYrm+66Ips2baJ79+60b9+ewYMHn5m+YsqUKWempj494d2PP/5Ix44d6dixI506dap06o2qstw4ArD3HCosKSP5VB5NwvzO/QKl1C8WjIdjW2v2mPXbwXUvVvj0bbfdxqOPPsqDDz4IwKxZs1i4cCE2m405c+YQGBhIWloa3bt3Z9CgQRWu2/vGG2/g6+vLjh072LJlC507dz7z3AsvvEBoaCilpaX069ePLVu28MgjjzBp0iSWLFlCeHj4r45V0TTTISEhVZ7u+rS77rqLV199ld69e/PMM8/w3HPPMXnyZF588UX279+Pt7f3mdtREydO5PXXX6dnz57k5ORgs9mq+l+5Qpa8ImimPYeUqlU6derEiRMnSElJYfPmzYSEhNCoUSOMMTz11FO0b9+eq666iiNHjnD8+PEKj5OYmHjmH+T27dvTvn37M8/NmjWLzp0706lTJ7Zt28b27dsrramiaaah6tNdg33CvIyMDHr37g3A3XffTWJi4pkahw8fzgcffICHh/17e8+ePXnssceYMmUKGRkZZ7ZfCEteEZzuQrr7RA794uu5uBqlaplKvrk709ChQ5k9ezbHjh3jtttuA+DDDz8kNTWV9evX4+npSUxMTLnTT5/L/v37mThxImvXriUkJISRI0ee13FOq+p01+fyzTffkJiYyFdffcULL7zA1q1bGT9+PAMHDmT+/Pn07NmThQsX0qpVq/OuFax0RZBzArbOhpIignw8iQzw1isCpWqR2267jU8++YTZs2czdOhQwP5tOjIyEk9PT5YsWcLBgwcrPcYVV1zBRx99BEBSUhJbtmwBICsrCz8/P4KCgjh+/DgLFiw485qKpsDu1asXc+fOJS8vj9zcXObMmUOvXr2qfV5BQUGEhIScuZp4//336d27N2VlZRw+fJi+ffvy0ksvkZmZSU5ODnv37qVdu3aMGzeOrl27nllK80JY54rgwDL4fDTc/yNEdaR5Pe05pFRt0qZNG7Kzs2nYsCENGjQAYPjw4dxwww20a9eOhISEc34zHjt2LKNGjSI+Pp74+Hi6dOkCQIcOHejUqROtWrWiUaNG9OzZ88xr7r//fvr3709UVBRLliw5s72iaaYruw1UkXfffZcxY8aQl5dHbGwsM2fOpLS0lBEjRpCZmYkxhkceeYTg4GCefvpplixZgpubG23atOG6666r9vv9lnWmoT65H6Z0hOtfgYR7mPBlEp9vOMLWZ6+psGFJKWWn01DXLtWdhto6t4ZCYsAWDCn22QPj6gWQU1jCsazzvw+olFJ1gXWCQASiOv0SBBHac0gppcBKQQDQsDMc3w7F+TSv5+g5dFyDQKmqqG23ka3qfP6erBUEUZ3AlMKxJML8vAj29WRPqgaBUudis9lIT0/XMLjEGWNIT0+v9iAz6/QaAohyjCJM2YA06krzSH/26BWBUucUHR1NcnIyqampri5FnYPNZiM6Orpar7FWEARGgV/kL+0Ekf4s3FbxKESllJ2npydNmzZ1dRnKSax1a0jE3k5wZAMAcZEBnMwtIj2n0MWFKaWU61grCMDeTpC2CwqzdbUypZTCqkGAgaNbaH7WnENKKWVVTgsCEZkhIidEJKmSffqIyCYR2SYiPzqrll+J6mT/M2UDDYJs+Hm56xWBUsrSnHlF8A7Qv6InRSQYmAoMMsa0AYY6sZZf+EdCYDSkbEREiIv01yBQSlma04LAGJMInKxklzuAL4wxhxz7n3BWLb/TsNOZBuNmGgRKKYtzZRtBCyBERJaKyHoRuauiHUXkfhFZJyLraqQfc1QnOLUf8k8RF+nPsawCsgqKL/y4SilVC7kyCDyALsBA4FrgaRFpUd6OxphpxpgEY0xCRETEhb/zmYFlm2geGQDAXr0qUEpZlCuDIBlYaIzJNcakAYlAh4vyzlEd7X+mbDjTc2jnsQtfAFoppWojVwbBl8DlIuIhIr7AZcCOi/LOPiEQ0hRSNtIkzJdwf29W70u/KG+tlFKXGqdNMSEiHwN9gHARSQYmAJ4Axpg3jTE7RORbYAtQBrxtjKmwq2mNa9gZDq1GROjRLIyV++wTaukiNUopq3FaEBhjbq/CPv8B/uOsGioV1QmSPoecE/SIDeOrzSnsT8sl1rFOgVJKWYX1RhafdlaDcY9mYQCs1NtDSikLsm4QNGgPCKRsICbMl/qBNlbs1SBQSlmPdYPAOwAiWp4ZYdyjWRir9+nCG0op67FuEIC9neDIBjCGHrFhpOUU6QR0SinLsXgQdIbcE5CV8ks7gd4eUkpZjMWD4JeZSBuF+tIw2EeDQCllOdYOgvptwc3jzNKVPZqFsWp/OmVl2k6glLIOaweBpw9Exv8SBLFhZOQV63QTSilLsXYQgP32UMpGe4OxjidQSlmQBkFUZ8g/BacOEBXsQ0yYr7YTKKUsRYPgdINx8jrA3k6wen86pdpOoJSyCA2C+u3ANxx2LQCge2wY2QUlbEvJdHFhSil1cWgQuLlDqwGwayEUF9AjVscTKKWsRYMAIP5GKMqBfUuJDLTRLMJPG4yVUpahQQDQ9ArwDoId8wB7O8Ha/ScpLi1zcWFKKeV8GgQAHl7Qsj/s/AZKi+kRG05uUSlbj2g7gVKq7tMgOC1+EBRkwIHldI8NBbSdQCllDRoEp8X1A08/2DGPMH9vWtYLYJW2EyilLECD4DRPH2h+Nez4GspK7e0EB05SVKLtBEqpuk2D4GzxN9inpT68hu6xYRQUl7HpcIarq1JKKafSIDhbi2vB3Rt2zKN7bCgisGJvmqurUkopp9IgOJt3ADS7EnZ8RbCPJ12bhPLlphRdvlIpVadpEPxW60GQeRhSNjKsWyP2p+Xq4DKlVJ2mQfBbLfrbF6vZMY8B7RoQ5OPJx2sOu7oqpZRyGg2C3/INhZhesH0eNg83hnRuyLdJR0nPKXR1ZUop5RQaBOVpPQhO7oUTO7i9W2OKSw2fb0h2dVVKKeUUTgsCEZkhIidEJOkc+3UVkRIRucVZtVRby4GAwI55tKgXQEKTED5ec1gbjZVSdZIzrwjeAfpXtoOIuAMvAYucWEf1BdSDxj1gu30Sujsua6yNxkqpOstpQWCMSQROnmO3h4HPgRPOquO8tR4EJ7ZB+l5tNFZK1WkuayMQkYbAYOCNKux7v4isE5F1qampzi8O7KOMAbbPxebpro3GSqk6y5WNxZOBccaYc07mY4yZZoxJMMYkREREOL8ygKBoe++h1dOgOF8bjZVSdZYrgyAB+EREDgC3AFNF5CYX1vN7fcZDzjFY/442Giul6iyXBYExpqkxJsYYEwPMBh4wxsx1VT3lirncflWwbBIU5WmjsVKqTnJm99GPgZVASxFJFpHRIjJGRMY46z2dou9T9hlJ181gQLsGBNo8tNFYKVWneDjrwMaY26ux70hn1XHBmvwBmvaGnyZjSxjFkM7RfLj6IOk5rQnz93Z1dUopdcF0ZHFV9H0KclNh7XTuuEwbjZVSdYsGQVU07g6xfeGn/9IixI2uMSHM/OkAuYUlrq5MKaUumAZBVfV9CvLSYM1bjOvfiqOZBfx38W5XV6WUUhdMg6CqGnWDZv1gxRQSGngxrGsjpi/fz/aULFdXppRSF0SDoDr6PgV56bBmGuP6tyLIx5O/zt1KWZmOK1BK1V4aBNURnQBxV8OKKYR4FPLXAfFsPJTBx2sPuboypZQ6bxoE1dXnScg/BavfZEjnhnSPDeWlBTtJzdY5iJRStZMGQXVFd4GWAyDxZeT4Nv5xUzvyi0v5xzfbXV2ZUkqdFw2C83HDf8EWBLPuJC6wlLG9m/HlphSW705zdWVKKVVtGgTnwz8Sbn0XMg7B3Ad4oE8zmoT58vSXSRQUl7q6OqWUqhYNgvPVuDtc/Tzs/Brb2tf5x01t2Z+WyxtL97q6MqWUqhYNggvR/QFofSN8/yy9PH9mUIcoXl+yh6U/X3oLrimlVEU0CC6ECAx6DUKbwWejeOHqcFrWD2DMB+tZe+Bcq3QqpdSlQYPgQtkC4bb3oSiHgHn38e7dnYgK9uGemWtJOpLp6uqUUuqcqhQEIuInIm6O31uIyCAR8XRuabVIZDzcMAUOrSR85T/5YPRlBPp4cteMNew5kePq6pRSqlJVvSJIBGyOBecXAXcC7zirqFqp/VDo9kdY9TpRq57ng3sScBPhzumrST6V5+rqlFKqQlUNAjHG5AFDgKnGmKFAG+eVVUv1/xdcNhZWTaXpkgf44O525BaWMOLt1TryWCl1yapyEIhID2A48I1jm7tzSqrF3Nzhuhfh2n/Bjq9ptXAE790ex/GsQu6cvprjWQWurlAppX6nqkHwKPAkMMcYs01EYoElTquqtuvxgH3A2bEtdFx4C+8PDudgeh4D/ruMxF2prq5OKaV+RYyp3hTKjkZjf2OMSybiT0hIMOvWrXPFW1ffodXw8TAQ4VD/mdy3WPj5eDYP9GnGY1e3wMNdO20ppS4OEVlvjEko77mq9hr6SEQCRcQPSAK2i8gTNVlkndT4Mhj9HXgH0HjerXzVdTO3J0Qxdelehk1bRUpGvqsrVEqpKt8aau24ArgJWAA0xd5zSJ1LeByM/h6aXoHX93/jXycfY+Z1Puw4msWAKctYvOO4qytUSllcVYPA0zFu4CZgnjGmGNBluarKPwLumAU3T4eMQ/T9cSg/df2JJoHujH53HU98tll7FSmlXKaqQfA/4ADgBySKSBNAF+utDhFodws8tBba30bw+inMcfs//tEpg7mbjtB34lKmJe6lqKTM1ZUqpSym2o3FZ14o4mGMKanhes6pVjUWV2bvEvj6UTh1gOwWQ3g+dwif7XUjNtyPp69vTd9Wka6uUClVh9REY3GQiEwSkXWOn5exXx2o89WsL4xdCb3+QsC++fzn2D0kdlxMgMlm1DtrGTVzDXtTdXoKpZTzVfXW0AwgG7jV8ZMFzKzsBSIyQ0ROiEhSBc8PF5EtIrJVRFaISIfqFF4nePlCv2fg4Q3Q7lYa75zB3NKH+LTtWrYcOM61ryQy4csk0nO0/UAp5TxVujUkIpuMMR3Pte03z18B5ADvGWPalvP8H4AdxphTInId8Kwx5rJz1VJnbg2V51gSfD8B9nxPaWAjPg+5lyd3N8fX04MH+sYxqmcMNk8d0K2Uqr4LvjUE5IvI5WcdsCdQaSd4Y0wiUOGk/MaYFcaYU46Hq4DoKtZSd9VvCyM+hzvn4u4bzK0HJ5AU81+GNMzgpW930u/lH/ly0xHKyrTDllKq5lQ1CMYAr4vIARE5ALwG/LEG6xiNfXxCuUTk/tPtE6mpFpiioVlfuP9HuH4yPqd289zRMaxsv4BoWwF/+mQTN7+5gt3Hs11dpVKqjqhWryERCQQwxmSJyKPGmMnn2D8G+Lq8W0Nn7dMXmApcboxJP1cNdfrWUHnyTsKSf8K66RhbMOvjHuGPSa3ILoI/XdWc+6+IxVOnqlBKnUNN3BoC7AFw1hxDj9VAYe2Bt4EbqxICluQbCgMnwh8TkYhWJGx9llX1/8MdcSX8Z+HPDJ76E9tTdEiHUur8XchXSbmQNxaRxsAXwJ3GmF0XcixLqN8ORs2HIW/heWovzx4dw7zLD3IsI59Bry3nle926WA0pdR5uZAgqPSekoh8DKwEWopIsoiMFpExIjLGscszQBgwVUQ2iYiF7vecJxFofyuM/QkadKT9uidZ0fwjhrbx57+LdzPoteW6TrJSqtoqbSMQkWzK/wdfAB9jjIezCquI5doIKlJWCstfsbcfBDZkbZeXeGCZF6dyi3joyjge7BunbQdKqTPOu43AGBNgjAks5yfAFSGgzuLmDlc8DqMXgZsbXZcMZ1nXlQxqG8bk73czeOpP/HxMexYppc5NvzLWdtEJ8Mdl0O5WbCsmMiltDLOvzOJoRgE3vLqcN5bupVTHHSilKqFBUBfYAmHI/+yD0cSdhBVjWNnkfwxrVsRL3+7kljdXaNuBUqpCGgR1SdxVMHYFXPMPvJJX8dyRe1nU7geOp6Zxw2vLeWzWJl0VTSn1O+c9DbWraGNxFWUfg++fg80fUeZfnwWR9/GXXfEY3Li3V1PG9G5GgM3T1VUqpS6SyhqLNQjqusNrYME4SNlAUVg8031G8tKeaML8vHn06hbc3rURHtq7SKk6r8ZGFqtaqFE3uO8HuGUmXmX5jE0ex9bYqVwVcpSn5yZx7eREFu84Tm37QqCUqjkaBFYgAm2HwINrof9LBJzawUtpD7OyxUdElh5n9LvrGP72am1QVsqi9NaQFRVkwvLJsGoqxhiSGg9n7IHeHCnwZEinaB6/tgUNgnxcXaVSqgZpG4EqX2YyLH4etnxKmW8ECyNH8+fd7cHNjft7xTKmTzN8vXTcoFJ1gbYRqPIFRcOQaXDfD7iFx3HdgRfZUv/vPNT4MFN+2HNmIZza9mVBKVU9GgQKGnaBUQtg6Lt4lebx0JEn2BT3Nq1tJ/nTJ5sY+uZKtiZr+4FSdZUGgbITgTY3wUNr4arnCD6+mrdzH+Kr9stJSTvFoNeXM272FlKzC11dqVKqhmkQqF/z8IbLH4WH1iItr6PdrqksD/gr/2p7jM83JNPv5aXMXp+st4uUqkM0CFT5ghrC0Hfgzrm4uXswbPdjbGr5Lj0j8nj8s83c885ajmUWuLpKpVQN0CBQlWvW1z5/Ub8J+CcnMjXzId5JOMDKfelc/cqPfLbusF4dKFXLaRCoc/Pwgl6PwYOrkXpt6ZP0FGvbzqVjpBdPzN7CqHfWcjRTJ7NTqrbSIFBVF9wYRn4DvR4nYMenvFc2jsl9vVi97yTXvJLI0p9PuLpCpdR50CBQ1ePuAf2ehjvnIPmnuGntCJZfdZDoYB/ueWct05fv11tFStUyGgTq/DTrC2N/gsY9CFvyf3zVYAYDWgbx96+389ScrRSVlLm6QqVUFWkQqPPnHwkjvoB+E/DYMZdXS//BY70i+XjNYe6cvppTuUWurlApVQUaBOrCuLnZG5KHzkSOrOORQ39m6o1RbDycwU1Tf2LPiWxXV6iUOgcNAlUz2gyGOz6Fk3sZsGYUnw9rSG5hCYNfX8HKvemurk4pVQkNAlVz4vrBXfOgIIN23w7lm2Fh1A+yMXLmGn7clerq6pRSFdAgUDWrUVf7BHYi1Js9mNnXu9Mswp/73l3Hom3HXF2dUqocGgSq5kXGwz0LwTeMoM+G8tlV+cRHBfLAhxv4ZstRV1enlPoNpwWBiMwQkRMiklTB8yIiU0Rkj4hsEZHOzqpFuUBIE7jnWwhtht8Xw/mkVxqdGgfz8Mcb+GJDsqurU0qdxZlXBO8A/St5/jqguePnfuANJ9aiXME/EkZ+BQ064DNnFB90O0j32DD+8tlmPlp9yNXVKaUcnBYExphE4GQlu9wIvGfsVgHBItLAWfUoF/EJgTvnQpM/4D1vLO+230bvFhE8NWcr//txr45CVuoS4Mo2gobA4bMeJzu2qbrG2x+GfwbNr8FzwWO8HbeCge0a8K8FOxn/uY5CVsrVakVjsYjcLyLrRGRdaqp2Q6yVPH3gtg+gzWA8Fk/gtQYLeKhPMz5dd5i7ZqwmI09HISvlKq4MgiNAo7MeRzu2/Y4xZpoxJsEYkxAREXFRilNO4OEFN0+HTiOQxH/zeMGrTLk5jg0HMxg8dQX7UnNcXaFSluTKIJgH3OXoPdQdyDTGaN/Cus7NHW54Fa54AjZ9yKCVw5g72EZWfjE3vf4TP+1Jc3WFSlmOM7uPfgysBFqKSLKIjBaRMSIyxrHLfGAfsAd4C3jAWbWoS4ybG1z5Nxj5NZQU0Xr+LSzutpaoQE/unrGGGcv3U1qmjchKXSxS23ptJCQkmHXr1rm6DFVT8k/B14/Bti8oie7OUzzMrD1Ch0bBvHBTW9o2DHJ1hUrVCSKy3hiTUN5ztaKxWNVhPiFwywwY/D88TmzjpdSxfNF9Hykncxj02nKe+2ob2QXFrq5SqTpNg0C5ngh0GAZjlyORrem86W+sCvs7T7c+zjsrDnDVpB+Zv/WojjlQykk0CNSlIyTGPmHdzdNxL8pk1N4/szn2f3TxTuGBDzdw98y17Dia5eoqlapzNAjUpcXNDdrdAg+tg2v+QWD6Jl7PfoRFTT8l5dBeBkxZxmOzNpF8Ks/VlSpVZ2hjsbq05Z2EZS/DmmkYcWNVxFAePtybLOPPnT2a8GDfOEL9vFxdpVKXvMoaizUIVO1w6gAs+SdsmUWZdyDfBg/j8UPdcffy44+9Yxl9eSw+Xu6urlKpS5YGgao7jiXB4udh90JKfOvxie/tPJvcmbBAPx6/piVDOkfj7iaurlKpS452H1V1R/22MHwWjFqAR1gMI9ImkxT5DINsm3li9mauf3U5y3fr6GSlqkODQNVOTf5gXwXt9k+weXnz16znWdv4dcLz9jJi+mpGzlzDruPZrq5SqVpBg0DVXiLQ8joY+xNc928isrbxXtFjfBP3JXsOHqb/5ESe+TKJzHwdkKZUZTQIVO3n7gmX/REe3ogkjKLNkc9ItP2FV5ut5eNV++j38lLmbEzWAWlKVUCDQNUdfmEw8GUYsxy3Bu0YmPwKW6Jeorf/Ef786WaGTVult4uUKocGgap76rWBu+bB0HfxKUxjYuaf+bbVfA4dO8GA/y7jn/N3kFtY4uoqlbpkaBCoukkE2twED61Buoyi1YEPWB7wFH+NO8i0xH1c80oiibt0tTulQINA1XW2ILh+EtyzCHfvAEYdGs+GVh8Q5Z7BXTPW8Phnm3WZTGV5GgTKGhpfBn9MhCufJvTwYmaV/pmpbX9mzsZkrpqUyLdJujiesi4NAmUdHl5wxeMwdgUSGc+APc+xqdnbxPtlM+aDDYz9YD0nsgtcXaVSF50GgbKe8DgYOR/6v0TA0ZW8V/AwM9rvYPHO41w9KZHP12tXU2UtGgTKmtzcoPsYeGAFUr8DV+76O5ti3qBHWC5/+Wwzo95ZS0pGvqurVOqi0CBQ1hYaC3d/BQMm4nt8PW9kPsinHTaydl8a17ySyIerD1JWplcHqm7TIFDKzQ263QcPrESa9OCyn//Dhqh/c329dP46J4k73l7FwfRcV1eplNNoECh1WkgTGD4bbp6Od/Zh/pX2MPNbL2bPEfvVwauLd1NQXOrqKpWqcRoESp1NxLFU5lqk/W203jedVcF/48Emybz83S6unZzIkp9PuLpKpWqUBoFS5fENhZumwl3z8HB345Ejj7M+biaNOcqomWu5/711HD6p6yarukGDQKnKxPaGsSvgyqcJO7GS9/IfZl6zr9iy+wBXv/Ijry7eTX6R3i5StZsuValUVWUfh6X/hA3vUeYVyBcBd/BkcndCAvx46Mo4buvaCG8PXTdZXZp0zWKlatLx7bDob7B3MQUBTZjhdjOvHO9IZHAAj/SLY0jnaDzd9WJbXVpctmaxiPQXkZ9FZI+IjC/n+cYiskRENorIFhEZ4Mx6lKoR9VrDnV/A8M+x+QXyQOYktoaOY6T7Ap79fC1XT/qRuRuPUKrjD1Qt4bQrAhFxB3YBVwPJwFrgdmPM9rP2mQZsNMa8ISKtgfnGmJjKjqtXBOqSYgzsWQzLJ8HBnyjyCuZTt4FMzOhNQEgEd/eI4daERgT5erq6UmVxrroi6AbsMcbsM8YUAZ8AN/5mHwMEOn4PAlKcWI9SNU8Eml8Fo+bDPYvwiunBnQUfst7/UZ6W6cxdsIDu/1rMX+dsZc8JXR1NXZqceUVwC9DfGHOv4/GdwGXGmIfO2qcBsAgIAfyAq4wx68s51v3A/QCNGzfucvDgQafUrFSNOL4NVrwK2+ZASQHJthZMy+3FnOIedGzemOGXNaZvq0htWFYXlUsai6sYBI85anhZRHoA04G2xpiyio6rt4ZUrZF/CrbOhvXvwvGtFLvZWEgPPijoyc9ebbmuQzSDOzUkoUkIIuLqalUdV1kQeDjxfY8Ajc56HO3YdrbRQH8AY8xKEbEB4YAO3VS1n0+IfQ6jrvdCygY8N7zHwK2zud5rCVnuIXy9sSsT11zGseAO3NipMYM6NiQu0t/VVSsLcuYVgQf2xuJ+2ANgLXCHMWbbWfssAD41xrwjIvHAYqChqaQovSJQtVpRLuxaCNvnYnYtQkryyXALZV5xFxaUdiM9tDP92kZzTet6dIgOxs1NrxRUzXDZOAJHd9DJgDswwxjzgog8D6wzxsxz9BR6C/DH3nD8f8aYRZUdU4NA1RmFObB7EWybg9n9HVKST574sqSkHT+UdiLJtxsJbVpwdet6dI8Nw+apbQrq/OmAMqUudYU5sG8J7FpI2a6FuOWeoAxhq2nG4pKOrJIO+DXtSq+W9bmiRQTNIvy0XUFViwaBUrVJWRkc2wy7FlG261skZSOCIQc/fiqNZ3lZW3b7JdC0ZQcubx5B99hQwvy9XV21usRpEChVm+Wmw/4fYd9SSvb8gEfWYQCOmjBWlMWzuiye1NAEYpq35Q9xEXRrGkqQjw5gU7+mQaBUXXJyH+xbStnepZTuX45nQToAx0woq8tasaYsnvTwBBrEtqNrbDhdY0KJCNArBqvTIFCqrjIG0nbBgeWU7l9G6f7leOWnApBh/FlX1pz1ZS05Etge/6Zd6di0AZ2bBBMb7q89kixGg0ApqzAG0vfCoZWUHlxF8YEV2DL3AVCMO0llTdlU1oyfPVpQ2qALDWNb07lJKB0bBxNo09tJdZkGgVJWlpsOh1djDq6k4OAaPI9vxqM0H4BTxp/NZc3YbJqR6t8K94YdadQkjvaNQmgTFYiftzPHnKqLSYNAKfWL0hJI3QFH1lN0cA3FB9fik7kHN+wzu6SbALaVxZBkmpIe0Aq3em0Ib9yKlg1Dad0gkIgAb+26WgtpECilKleUa58s7+hm8g+tpyR5E76Zu3A39mU4C40H+0wDdplGHPZoQlFoC7zqtSQkuiVN6wUTF+GvAXGJ0yBQSlVfSSGk7oQTOyhI2UZ+8lY803fiX3D0zC6lRjhiwjlg6nPEPYpcvyYQEoNXWGMC68fSoF59Gof5Ui/Apo3TLqZBoJSqOYXZkPozJn0PuSm7yD/2M3JqH/45B7GV5f5q1yzjQ4oJ5yjhZHnVo9AngjK/+rgHNcAnNAr/8EaERkYREehDmJ83Xh66xKezuGr2UaVUXeQdANEJSHQC/h3sE4UB9h5LuWmQcYjikwfJPraP/PSD+J06ROucI/gV7sU/OwuygWO/HK7UCCcJYJ8JIsstkFyPUIq8QyixhYFvKG6+oXj6h+EdGI5vcAQBIREEBoYS7Oel8y/VEA0CpVTNEAH/CPCPwDO6C6Hty9mnpBByjlOWdYzstMPkpCVTeCqF0pw0PHLTqFd4ElvRfvzyNuKfmwPp5b9ViXEjC1+O40eumz/5bgEUegZQ7BlAqWcgxhYE3kG4+Qbj4ROEp38I3n7B2AKC8QkIxT8wmAAfL10cyEGDQCl18Xh4Q3Bj3IIbE9S4G0GV7VtSBAUZFGWnkZuRSl5GKvlZaRRnp1Gan4HJz8CtMBOPwkxCi7PwLk7DpzAHX5OLN8XnLCXb+HAKH3LFlwI3Pwrd/Shy96PE048SzwDw8sd4BSC2ANxtAbj7BOLpG4SnbyA230Bs/kH4+Afh5xeAr5dHrW4D0SBQSl2aPLzAPxIv/0i8GtjXs62y4gLK8jPJy04nN+sUBdknKcrNoDg3k9L8DMoKsqAgCynMwq04F4/iHIJKcvAuTsVWmIuvycOXgiq9VakRcrCRhw8FYqPQzYdCNx9K3H0odvel1MP+g6cPxtMP8fIFLz/cvfxwt/nhbvPHw+aPl48fnrYAbL72H28/f3y9vfFwd367iQaBUqru8bTh5mnDP7Ae/g3P8xhlZZiibApyMsnPyaQgJ4OCnAyK8rMoyc+mtCCH0oJsTGEOUpSDFOfiVpyLe0ke3qV5+Jdm4FVyFO/8fLxNAT4U4ElptUooNB7k4E2heFOAjeRmt9HzzmfP84QqpkGglFLlcXNDbEH42ILwCa+hY5YUUVyQQ35uNgV5WRTm51B8+qcgh9KCXEoLczFFeZiiXCjOh+I83IrzcCvNxzc0qoYK+TUNAqWUulg8vPD0D8XTP5RAV9dyFu20q5RSFqdBoJRSFqdBoJRSFqdBoJRSFqdBoJRSFqdBoJRSFqdBoJRSFqdBoJRSFlfr1iMQkVTg4Hm+PBxIq8FyahOrnruet7XoeVesiTEmorwnal0QXAgRWVfRwgx1nVXPXc/bWvS8z4/eGlJKKYvTIFBKKYuzWhBMc3UBLmTVc9fzthY97/NgqTYCpZRSv2e1KwKllFK/oUGglFIWZ5kgEJH+IvKziOwRkfGursdZRGSGiJwQkaSztoWKyHcistvxZ7WWf60NRKSRiCwRke0isk1E/uTYXqfPXURsIrJGRDY7zvs5x/amIrLa8Xn/VES8XF2rM4iIu4hsFJGvHY/r/HmLyAER2Soim0RknWPbBX3OLREEIuIOvA5cB7QGbheR1q6tymneAfr/Ztt4YLExpjmw2PG4rikB/mKMaQ10Bx50/B3X9XMvBK40xnQAOgL9RaQ78BLwijEmDjgFjHZdiU71J2DHWY+tct59jTEdzxo7cEGfc0sEAdAN2GOM2WeMKQI+AW50cU1OYYxJBE7+ZvONwLuO398FbrqYNV0MxpijxpgNjt+zsf/j0JA6fu7GLsfx0NPxY4ArgdmO7XXuvAFEJBoYCLzteCxY4LwrcEGfc6sEQUPg8FmPkx3brKKeMeao4/djQD1XFuNsIhIDdAJWY4Fzd9we2QScAL4D9gIZxpgSxy519fM+Gfg/oMzxOAxrnLcBFonIehG537Htgj7nuni9xRhjjIjU2T7DIuIPfA48aozJsn9JtKur526MKQU6ikgwMAdo5dqKnE9ErgdOGGPWi0gfF5dzsV1ujDkiIpHAdyKy8+wnz+dzbpUrgiNAo7MeRzu2WcVxEWkA4PjzhIvrcQoR8cQeAh8aY75wbLbEuQMYYzKAJUAPIFhETn/Rq4uf957AIBE5gP1W75XAf6n7540x5ojjzxPYg78bF/g5t0oQrAWaO3oUeAHDgHkurulimgfc7fj9buBLF9biFI77w9OBHcaYSWc9VafPXUQiHFcCiIgPcDX29pElwC2O3erceRtjnjTGRBtjYrD///yDMWY4dfy8RcRPRAJO/w5cAyRxgZ9zy4wsFpEB2O8pugMzjDEvuLYi5xCRj4E+2KelPQ5MAOYCs4DG2KfwvtUY89sG5VpNRC4HlgFb+eWe8VPY2wnq7LmLSHvsjYPu2L/YzTLGPC8isdi/KYcCG4ERxphC11XqPI5bQ48bY66v6+ftOL85jocewEfGmBdEJIwL+JxbJgiUUkqVzyq3hpRSSlVAg0AppSxOg0AppSxOg0AppSxOg0AppSxOg0Cp3xCRUsfMjqd/amyiOhGJOXtmWKUuBTrFhFK/l2+M6ejqIpS6WPSKQKkqcswD/2/HXPBrRCTOsT1GRH4QkS0islhEGju21xOROY61AjaLyB8ch3IXkbcc6wcscowIVsplNAiU+j2f39wauu2s5zKNMe2A17CPVAd4FXjXGNMe+BCY4tg+BfjRsVZAZ2CbY3tz4HVjTBsgA7jZqWej1DnoyGKlfkNEcowx/uVsP4B9EZh9jgnujhljwkQkDWhgjCl2bD9qjAkXkVQg+uwpDhxTZH/nWEAEERkHeBpj/nERTk2pcukVgVLVYyr4vTrOnvumFG2rUy6mQaBU9dx21p8rHb+vwD4DJsBw7JPfgX3JwLFwZvGYoItVpFLVod9ElPo9H8eKX6d9a4w53YU0RES2YP9Wf7tj28PATBF5AkgFRjm2/wmYJiKjsX/zHwscRalLjLYRKFVFjjaCBGNMmqtrUaom6a0hpZSyOL0iUEopi9MrAqWUsjgNAqWUsjgNAqWUsjgNAqWUsjgNAqWUsrj/B8SfAmnH+RAbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss values\n",
    "plt.plot(results['loss'], label='training loss')\n",
    "plt.plot(results['val_loss'], label='validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEXkbFI8T87C"
   },
   "source": [
    "**NOTE:** If you don't see the training and validation loss lines, its likely because they are overlapping. Try running the model again to see if you get a slightly different result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ba2_joZhT87D"
   },
   "source": [
    "## Evaluate and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJGfPsT0T87D"
   },
   "source": [
    "Evaluating your models and making predictions is also simple using Keras. Again, all you have to do is call the `.evaluate` and `.predict` methods on your model, and pass in the testing data you would like to use.\n",
    "\n",
    "- `tf.keras.Model.evaluate` returns a list of two values: `[loss, accuracy_score]` (this may change based on what scoring metric you are using for your model).\n",
    "\n",
    "\n",
    "- `tf.keras.Model.predict` returns a NumPy array, the shape of which is determined by the structure of the model and the loss function you specified. For instance, in our model, `.predict` will return the probability scores for each class in the shape of `(n_observations, n_classes)`.\n",
    "\n",
    "Instead of having to save the model, reload it, and restore the weights, Keras stores the trained model variables and makes them readily accessible for you. This makes testing and making predictions much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161131,
     "status": "ok",
     "timestamp": 1565547854904,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "EQAB_65vT87D",
    "outputId": "e3541bda-d5f5-4841-f021-ded3f50432b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4540/4540 [==============================] - 24s 5ms/step - loss: 0.6799 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.679924726486206, 0.7273309230804443]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 163121,
     "status": "ok",
     "timestamp": 1565547856900,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "iNLLjh-cT87F",
    "outputId": "a7eda285-4f49-4707-bba3-6d2bce11b38f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 09:33:39.755534: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145253, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08135367, 0.85695404, 0.01089942, 0.00420559, 0.02524661,\n",
       "        0.01306139, 0.00827933],\n",
       "       [0.00826601, 0.4241238 , 0.27449888, 0.0461692 , 0.06532174,\n",
       "        0.17352325, 0.00809714],\n",
       "       [0.022943  , 0.83286697, 0.04543072, 0.01043285, 0.04075674,\n",
       "        0.04232062, 0.00524907],\n",
       "       [0.13470563, 0.8138213 , 0.00694003, 0.00324623, 0.02160292,\n",
       "        0.00890617, 0.01077776],\n",
       "       [0.06220385, 0.8070719 , 0.03402975, 0.01139125, 0.04015428,\n",
       "        0.03316589, 0.0119831 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(X_test, batch_size=32)\n",
    "print(result.shape)\n",
    "result[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlGuPBL9T87M"
   },
   "source": [
    "# Basic Fine-Tuning of Neural Networks\n",
    "\n",
    "Alright, now that we can quickly whip up a fancy neural network using `tf.keras` with just a few lines of code, this raises the question: How do we decide on the proper model architecture for our task? Indeed, the flexibility of neural nets can be one their main drawbacks as there are tons of hyperparameters to tweak. Not only can you use any imaginable network topology (how neurons are interconnected), but even with a simple feedforward network you can change the number of layers, the number of neurons per layer, the type of activation function to use in each layer, the weight initialization logic, and much more!\n",
    "\n",
    "Of course, you can use grid search with cross-validation, but this will take a lot of time with neural nets, and you will only be able to explore a tiny part of the hyperparameter space. Fortunately, there are some pretty basic rules to follow when developing your model that will help guide you. We will go over many of these rules in the next module when we talk about optimizing deep neural networks. For now, we'll cover a couple basic tips to get you started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qa_oy6I_T87N"
   },
   "source": [
    "## Choosing the Number of Hidden Layers\n",
    "\n",
    "For many problems, a single hidden layer will get you reasonable results. It has actually been shown that a simple feedforward network with just one hidden layer can model even the most complex functions provided it has enough neurons. While this might be a decent approach for some problems, the fact is that deep networks have a much higher \"parameter efficiency\" than shallow ones &mdash; they can model complex functions using exponentially fewer neurons than shallow nets, making them much faster to train. The reason for this is that **real-world data is often structured in a hierarchical fashion**, and deep neural networks can take advantage of this by modeling increasing levels of granularity at each layer. Take an image classification deep neural net, for example:\n",
    "\n",
    "- lower hidden layers are able to model low-level structures (e.g. line segments of various shapes and orientations),\n",
    "- intermediate hidden layers combine these low-level structures to model intermediate-level structures (e.g. squares, circles), \n",
    "- and the highest hidden layers and the output layer combine these intermediate structures to model high-level structures (e.g. faces). \n",
    "\n",
    "This hierarchical architecture also helps deep neural networks converge faster to a good solution, and improves their ability to generalize to new datasets. So in general, for many problems you can start with just one or two hidden layers and it will work just fine. But for more complex problems, you can gradually ramp up the number of hidden layers, until you start overfitting the training set. Very complex tasks, such as large image classification or speech recognition, typically require networks with dozens of layers, and they need a huge amount of training data. However, you will rarely have to train such networks from scratch &mdash; it is much more common to reuse parts of a pre-trained network that performs a similar task. This is called **transfer learning**, and is a very common practice in image recognition tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZmU46mIT87N"
   },
   "source": [
    "## Choosing the Number of Neurons\n",
    "\n",
    "The number of neurons in the input and output layers is determined by the type of inputs and outputs your task requires. For example, the MNIST task, for which your model tries to classify images of size 28x28 into 10 classes, requires:\n",
    "\n",
    "- $28 \\cdot 28 = 784$ input neurons\n",
    "\n",
    "\n",
    "- $10$ output neurons\n",
    "\n",
    "However, for the hidden layers, the process is not as simple. In general, you will need to experiment to find the best approach for your model. A good place to start is somewhere **between 32 and 128 neurons per layer**. Anything outside of that range and you risk underfitting or overfitting the the training set. One strategy for choosing the number of neurons per hidden layer is to make all layers have same number of neurons, and then gradually increase them until the model starts overfitting the training data. In general, it's better to increase the number of layers rather than the number of neurons per layer. But again, this is still an art, and will always depend on the dataset you are using. \n",
    "\n",
    "A simpler approach is to pick a model with more layers and neurons than you actually need, then use early stopping to prevent it from overfitting (and other regularization techniques &mdash; especially dropout, as we will see in the next module)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of Module**\n",
    "\n",
    "You have reached the end of this module.\n",
    "\n",
    "If you have any questions, please reach out to your peers using the discussion boards. If you\n",
    "and your peers are unable to come to a suitable conclusion, do not hesitate to reach out to\n",
    "your instructor on the designated discussion board.\n",
    "\n",
    "When you are comfortable with the content, you may proceed to the next module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wU7AbnwhT87O"
   },
   "source": [
    "# References\n",
    "\n",
    "- Google, (n.d.). tf.layers. Tensorflow core 1.13 Python. *Tensorflow documentation.* Retrieved from https://www.tensorflow.org/api_docs/python/tf/layers\n",
    "\n",
    "\n",
    "- Google, (n.d.). tf.GraphKeys. Tensorflow core 1.13 Python. *Tensorflow documentation.* Retrieved from https://www.tensorflow.org/api_docs/python/tf/GraphKeys\n",
    "\n",
    "\n",
    "- Google, (n.d.). tf.keras.layers.Lambda.  Tensorflow core 1.13 Python. *Tensorflow documentation.* Retrieved from https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda\n",
    "\n",
    "\n",
    "- Keras contributors, (n.d.). Getting started with the Keras Functional API. *Keras documentation.* Retrieved from https://keras.io/getting-started/functional-api-guide/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Module10_Part2_Edited_by_ML_MC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
